# YattaTeam2025-
This repository contains all official documentation, technical resources, and collaborative materials developed by the Yatta Team for the WRO Future Engineers Contest
Navigation Menu
YattaTeam2025-2026

Code
Issues
Pull requests
 0 stars
 0 forks
 0 watching
 [Number] Branches
 [Number] Tags
 Activity
Public repository
mohamadAldababseh/YattaTeam2025-2026
Name	
3dmodels
car photos
code
electrical-schematics
team photos
video
README.md
Repository files navigation
README

Engineering Materials
This repository contains all official documentation, technical resources, and collaborative materials developed by the Yatta Team for the WRO Future Engineers Contest in the season 2025-2026.
Content
| Folder Name | Description |
|---|---|
| team photos | Contains photos of the team. |
| car photos | Contains photos of the vehicle. |
| video | Contains the video.md file with the link to the vehicle demonstration video. |
| electrical-schematics | Contains diagrams about the electrical design and circuit. |
| code | Contains the source code that is used for the control system. |
| 3dmodels | Contains 3D models and design files of the custom vehicle parts. |
Hardware
| HARDWARE PARTS | References |
|---|---|
| Chassis | TBD (To Be Determined) |
| Main-Controller | TBD (e.g., NVIDIA Jetson Nano/Raspberry Pi 5) |
| Secondary-Controller | TBD (e.g., Arduino Mega 2560/Raspberry Pi Pico) |
| Sensors | TBD (e.g., Lidar, Stereo Camera, High-Precision IMU) |
| Actuators | TBD (e.g., High-Torque Stepper Motors with Encoder) |
| Other-Parts | TBD (e.g., Power Management System, communication modules) |


Software

We are utilizing a modern main processing unit (RPI 5/Jetson) to run complex vision algorithms, while a secondary microcontroller handles real-time sensor data acquisition and low-level motor control.
Code Basic Idea
The core program leverages asynchronous programming and is divided into dedicated threads/processes to ensure concurrent and efficient execution of critical tasks such as perception, localization, and control.
PERCEPTION-THREAD
In the PERCEPTION-THREAD, frames from the camera (and potentially other visual sensors) are read and processed using libraries like OpenCV. This thread is responsible for identifying key track features (lines, obstacles, markers) and determining the desired path correction.
LOCALIZATION-THREAD
This thread integrates data from the IMU (gyroscope) and encoders to maintain accurate position and heading relative to the starting point. It performs sensor fusion to provide reliable, low-latency state estimation for the control system.
PLANNING-THREAD
The PLANNING-THREAD acts as the decision-maker. Based on the current location from the LOCALIZATION-THREAD and the perceived environment from the PERCEPTION-THREAD, it calculates the optimal maneuver (speed, turn angle, lane change) for the vehicle.
CONTROL-THREAD
The CONTROL-THREAD executes the commands generated by the planning thread by sending appropriate signals to the actuators (motors and servos) via the secondary controller, ensuring the vehicle follows the calculated trajectory smoothly.
Turning
The turning mechanism is optimized for high-speed, precise 90-degree and 180-degree maneuvers. It uses the real-time angle from the LOCALIZATION-THREAD to perform closed-loop control, ensuring the vehicle achieves the target heading with minimal overshoot. The desired angle is dynamically set by the PLANNING-THREAD.
Avoiding Walls
Obstacle and wall avoidance is achieved by fusing proximity sensor data (e.g., Lidar/Ultrasonics) with vision-based distance estimation. A robust control algorithm, such as a Model Predictive Control (MPC) or advanced PID controller, calculates the necessary steering correction to maintain a safe distance from track boundaries while maximizing vehicle speed and stability.
LAPS/Finish Line Detection
Lap counting is handled by a specialized Computer Vision module within the PERCEPTION-THREAD. This module is trained to reliably detect the finish line pattern and color, ensuring accurate lap completion registration (e.g., 3 LAPS detection) under varying lighting conditions. The system ensures that the finish line is only counted once per lap direction.
ุง
